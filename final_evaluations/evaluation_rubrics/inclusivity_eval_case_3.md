LLM Evaluation Prompt — Case 3: Detailed Inclusivity Specification

Survey Title:
Inclusivity Evaluation of LLM Generated Code

Survey Statement:
This survey evaluates security mechanisms generated by Large Language Models (LLMs) with a focus on inclusivity. The goal is to assess how effectively LLMs can generate code that supports inclusive and secure user experiences, especially for neurodivergent users.

Research Focus: 1. Effectiveness – How well do LLMs generate code that meets security and inclusivity requirements? 2. Influencing Factors – How do prompt design, model choice, and specification detail affect the inclusivity and security of generated code? 3. Evaluation – How do human and LLM reviewers assess inclusivity and security gaps in LLM-generated code?

Participants evaluate three cases representing different levels of inclusivity specification.

⸻

User Story:
Helena is a 67-year-old patient with chronic heart disease and ADHD. She calls the hospital to book an appointment to review her medication dosage. Due to changed privacy conditions she must accept the updated terms by logging into her user account before hospital authorities can book an appointment. Authentication requires a strong password which she has forgotten, so she must reset her password to access the account and accept the privacy statement.

Inclusivity Description:
People with ADHD can lose track of multi-step tasks, get easily distracted, and feel overwhelmed by unclear instructions or time pressure. The login and password reset flow must be forgiving, clear, and low-stress. Avoid dense instructions, timeouts, or unexpected page changes. Support memory and focus by showing visible progress and reminders of the next step.

Additional Requirements:
• Keep the process simple and structured with clear, step-by-step guidance
• Use straightforward and consistent language
• Provide clear feedback at each step so the user knows what has happened and what to do next
• Allow enough time for actions without timeouts
• Reduce visual and cognitive distractions
• Ensure the user can pause and return without losing progress
• Make help options easy to find and access

Additional Context:
Screenshots of all application steps are provided with this prompt.

⸻

Evaluation Criteria (Scale 1–5):
1 = Strongly Disagree
2 = Disagree
3 = Neutral
4 = Agree
5 = Strongly Agree

⸻

Questionnaire

Attention 1. User interface is clean and does not have moving images or pop-ups 2. Important items clearly stand out 3. It is easy for the user to find what she needs quickly

Memory 4. The user does not need to remember many rules or steps 5. Options like password manager, autofill, or “remember me” are present 6. The user can easily recognize saved or familiar items

Comprehension 7. Text is short, clear, and easy to read 8. Error messages describe the problem and how to fix it 9. Examples show what to type or how to do a step

Decision Making 10. Choices such as password, code, or face login are clear 11. The user is not provided with too many choices at one time 12. The system clearly informs the outcome of each action

Learning 13. The user gets help or short tips for new steps 14. The user can easily try again if she makes a mistake 15. The design stays consistent so the user can learn it over time

⸻

Instruction to the LLM:
Using the screenshots provided, evaluate each of the 15 statements according to the 1–5 scale.

Respond only in the following format:

1: [score]
2: [score]
3: [score]
...
15: [score]

No explanations, text, or additional formatting.
