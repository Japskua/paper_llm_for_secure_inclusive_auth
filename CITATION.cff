cff-version: 1.2.0
title: "Experimental Dataset for Evaluating Security and Inclusivity in LLM-Generated Code"
message: "If you use this dataset, please cite it using the metadata from this file."
type: dataset
authors:
  - family-names: "Naqvi"
    given-names: "Bilal"
    email: "syed.naqvi@lut.fi"
    affiliation: "LUT University"
    orcid: "https://orcid.org/0000-0000-0000-0000"
  - family-names: "Parkkila"
    given-names: "Janne"
    affiliation: "LUT University"
  - family-names: "bin Shahid"
    given-names: "Waleed"
    affiliation: "Royal Holloway, University of London"
  - family-names: "Afzal"
    given-names: "Hammad"
    affiliation: "University of Leicester"
repository-code: "https://github.com/[organization]/paper_llm_for_secure_inclusive_auth"
url: "https://github.com/[organization]/paper_llm_for_secure_inclusive_auth"
abstract: >-
  This repository contains the complete experimental dataset and replication
  materials for evaluating security and inclusivity in Large Language Model
  (LLM)-generated authentication code. The dataset includes action prompts
  with varying inclusivity specifications, LLM-generated TypeScript code
  artifacts, evaluation rubrics based on OWASP Top 10 and cognitive
  accessibility dimensions, and evaluation scores from both human experts
  and five LLM evaluators.
keywords:
  - large language models
  - LLM
  - code generation
  - security
  - inclusivity
  - accessibility
  - OWASP
  - controlled experiment
  - software quality
  - authentication
license: MIT
version: "1.0.0"
date-released: "2025-01-01"
preferred-citation:
  type: article
  authors:
    - family-names: "Naqvi"
      given-names: "Bilal"
    - family-names: "Parkkila"
      given-names: "Janne"
    - family-names: "bin Shahid"
      given-names: "Waleed"
    - family-names: "Afzal"
      given-names: "Hammad"
  title: "Evaluating Security and Inclusivity in LLM-Generated Code: A Controlled Experiment"
  journal: "Information and Software Technology"
  year: 2025
  notes: "Under review"
